var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = NLPMetrics","category":"page"},{"location":"#NLPMetrics","page":"Home","title":"NLPMetrics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for NLPMetrics.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [NLPMetrics]","category":"page"},{"location":"#NLPMetrics._f_p_r_lcs-Tuple{Any, Any, Any}","page":"Home","title":"NLPMetrics._f_p_r_lcs","text":"_f_p_r_lcs(llcs, m, n)\n\nComputes the LCS-based F-measure score\n\nArguments:\n\nllcs: Length of LCS\nm: number of words in reference summary\nn: number of words in candidate summary\n\nSource: (http://research.microsoft.com/en-us/um/people/cyl/download/papers/rouge-working-note-v1.3.1.pdf)\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._get_ngrams-Tuple{Any, Any}","page":"Home","title":"NLPMetrics._get_ngrams","text":"_get_ngrams(n, text)\n\nCalcualtes n-grams. Returns a set of n-grams.\n\nArguments:\n\nn: provide which n-grams to calculate\ntext: An array of tokens\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._get_word_ngrams-Tuple{Any, Any}","page":"Home","title":"NLPMetrics._get_word_ngrams","text":"_get_word_ngrams(n, sentences)\n\nCalculates word n-grams for multiple sentences.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._lcs-Tuple{Any, Any}","page":"Home","title":"NLPMetrics._lcs","text":"_lcs(x, y)\n\nUtility function to compute the length of the longest common subsequence (lcs) between two strings. The implementation below uses a DP programming algorithm and runs in O(nm) time where n = len(x) and m = len(y).\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._len_lcs-Tuple{Any, Any}","page":"Home","title":"NLPMetrics._len_lcs","text":"_len_lcs(x, y)\n\nReturns the length of the Longest Common Subsequence between sequences x and y.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._recon_lcs-Tuple{Any, Any}","page":"Home","title":"NLPMetrics._recon_lcs","text":"_recons_lcs(x, y)\n\nReturns the Longest Subsequence between x and y.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._split_into_words-Tuple{Any}","page":"Home","title":"NLPMetrics._split_into_words","text":"_split_into_words(sentences)\n\nSplits multiple sentences into words and flattens the result\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics._union_lcs-Tuple{Any, Any}","page":"Home","title":"NLPMetrics._union_lcs","text":"_union_lcs(evaluated_sentences, reference_sentence)\n\nReturns LCSu(ri, C) which is the LCS score of the union longest common subsequence between reference sentence ri and candidate summary C.\n\nArguments:\n\nevaluated_sentences: the sentences that have been picked by the summarizer\nreference_sentence: one of the sentences in the reference summaries\n\nFor example, if ri= w1 w2 w3 w4 w5, and C contains two sentences: c1 = w1 w2 w6 w7 w8 and c2 = w1 w3 w8 w9 w5, then the longest common subsequence of ri and c1 is “w1 w2” and the longest common subsequence of ri and c2 is “w1 w3 w5”. The union longest common subsequence of ri, c1, and c2 is “w1 w2 w3 w5” and LCSu(ri, C) = 4/5.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics.bleu_score-Tuple{Any, Any}","page":"Home","title":"NLPMetrics.bleu_score","text":"bleu_score(reference_corpus, translation_corpus; max_order=4, smooth=false)\n\nComputes BLEU score of translated segments against one or more references. Returns the BLEU score, n-gram precisions, brevity penalty,  geometric mean of n-gram precisions, translationlength and  referencelength\n\nArguments\n\nreference_corpus: list of lists of references for each translation. Each reference should be tokenized into a list of tokens.\ntranslation_corpus: list of translations to score. Each translation should be tokenized into a list of tokens.\nmax_order: maximum n-gram order to use when computing BLEU score. \nsmooth=false: whether or not to apply. Lin et al. 2004 smoothing.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics.get_ngrams-Tuple{Any, Any}","page":"Home","title":"NLPMetrics.get_ngrams","text":"get_ngrams(segment, max_order)\n\nExtracts all n-grams upto a given maximum order from an input segment. Returns the counter containing all n-grams upto max_order in segment with a count of how many times each n-gram occurred.\n\nArguments\n\nsegment: text segment from which n-grams will be extracted.\nmax_order: maximum length in tokens of the n-grams returned by this methods.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics.rouge-Tuple{Any, Any}","page":"Home","title":"NLPMetrics.rouge","text":"rouge(hypotheses, references)\n\nCalculates average rouge scores for a list of hypotheses and references.\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics.rouge_l_sentence_level-Tuple{Any, Any}","page":"Home","title":"NLPMetrics.rouge_l_sentence_level","text":"rouge_l_sentence_level(evaluated_sentences, reference_sentences)\n\nComputes ROUGE-L (sentence level) of two text collections of sentences.\n\nCalculated according to:   Rlcs = LCS(X,Y)/m,   Plcs = LCS(X,Y)/n,   Flcs = ((1 + beta^2)*Rlcs*Plcs) / (Rlcs + (beta^2) * P_lcs)\n\nwhere:   X = reference summary   Y = Candidate summary   m = length of reference summary   n = length of candidate summary\n\nArgumnets:\n\nevaluated_sentences: the sentences that have been picked by the summarizer\nreference_sentences: the sentences from the referene set\n\nSource: (http://research.microsoft.com/en-us/um/people/cyl/download/papers/rouge-working-note-v1.3.1.pdf)\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics.rouge_l_summary_level-Tuple{Any, Any}","page":"Home","title":"NLPMetrics.rouge_l_summary_level","text":"rouge_l_summary_level(evaluated_sentences, reference_sentences)\n\nComputes ROUGE-L (summary level) of two text collections of sentences.\n\nCalculated according to:   Rlcs = SUM(1, u)[LCS<union>(ri,C)]/m   Plcs = SUM(1, u)[LCS<union>(ri,C)]/n   Flcs = ((1 + beta^2)*Rlcs*Plcs) / (Rlcs + (beta^2) * P_lcs)\n\nwhere:   SUM(i,u) = SUM from i through u   u = number of sentences in reference summary   C = Candidate summary made up of v sentences   m = number of words in reference summary   n = number of words in candidate summary\n\nArguments:\n\nevaluated_sentences: the sentences that have been picked by the summarizer\nreference_sentence: the sentences in the reference summaries\n\nSource: (http://research.microsoft.com/en-us/um/people/cyl/download/papers/rouge-working-note-v1.3.1.pdf)\n\n\n\n\n\n","category":"method"},{"location":"#NLPMetrics.rouge_n-Tuple{Any, Any}","page":"Home","title":"NLPMetrics.rouge_n","text":"rouge_n(evaluated_sentences, reference_sentences; n=2)\n\nComputes ROUGE-N of two text collections of sentences. Returns f1, precision, recall for ROUGE-N.\n\nArguments:\n\nevaluated_sentences: the sentences that have been picked by the summarizer\nreference_sentences: the sentences from the referene set\nn: size of ngram.  Defaults to 2.\n\nSource: (http://research.microsoft.com/en-us/um/people/cyl/download/   papers/rouge-working-note-v1.3.1.pdf)\n\n\n\n\n\n","category":"method"}]
}
