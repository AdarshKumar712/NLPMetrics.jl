var documenterSearchIndex = {"docs":
[{"location":"general/#General","page":"General","title":"General","text":"","category":"section"},{"location":"general/","page":"General","title":"General","text":"Here are some of the metrics for in-general use case like precision, recall, accuracy.","category":"page"},{"location":"general/","page":"General","title":"General","text":"(to be updated soon)","category":"page"},{"location":"general/#Accuracy","page":"General","title":"Accuracy","text":"","category":"section"},{"location":"general/#Precision","page":"General","title":"Precision","text":"","category":"section"},{"location":"general/#Recall","page":"General","title":"Recall","text":"","category":"section"},{"location":"general/#F1-Score","page":"General","title":"F1 Score","text":"","category":"section"},{"location":"general/#Confusion-Matrix","page":"General","title":"Confusion Matrix","text":"","category":"section"},{"location":"summarization/#Summarization-Metrics","page":"Summarization","title":"Summarization Metrics","text":"","category":"section"},{"location":"summarization/","page":"Summarization","title":"Summarization","text":"Metric Functions to evaulate models for the task for Summarization.","category":"page"},{"location":"summarization/#Rouge-Score","page":"Summarization","title":"Rouge Score","text":"","category":"section"},{"location":"summarization/","page":"Summarization","title":"Summarization","text":"Metrics.rouge_n\nMetrics.rouge_l_sentence_level\nMetrics.rouge_l_summary_level\nMetrics.rouge","category":"page"},{"location":"tm/#Translation-Metrics","page":"Translation","title":"Translation Metrics","text":"","category":"section"},{"location":"tm/","page":"Translation","title":"Translation","text":"Metric Functions to evaulate models for the task for Machine Translation.","category":"page"},{"location":"tm/#BLEU-Score","page":"Translation","title":"BLEU Score","text":"","category":"section"},{"location":"tm/","page":"Translation","title":"Translation","text":"NLPMetrics.bleu_score","category":"page"},{"location":"tm/#NLPMetrics.bleu_score","page":"Translation","title":"NLPMetrics.bleu_score","text":"bleu_score(reference_corpus, translation_corpus; max_order=4, smooth=false)\n\nComputes BLEU score of translated segments against one or more references. Returns the BLEU score, n-gram precisions, brevity penalty,  geometric mean of n-gram precisions, translationlength and  referencelength\n\nArguments\n\nreference_corpus: list of lists of references for each translation. Each reference should be tokenized into a list of tokens.\ntranslation_corpus: list of translations to score. Each translation should be tokenized into a list of tokens.\nmax_order: maximum n-gram order to use when computing BLEU score. \nsmooth=false: whether or not to apply. Lin et al. 2004 smoothing.\n\n\n\n\n\n","category":"function"},{"location":"tut/#Tutorials","page":"Tutorials","title":"Tutorials","text":"","category":"section"},{"location":"tut/","page":"Tutorials","title":"Tutorials","text":"To be updated soon...","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = NLPMetrics","category":"page"},{"location":"#NLPMetrics","page":"Home","title":"NLPMetrics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"NLPMetrics is a Julia based package to facilitate evaluation of common NLP Tasks like Translation, Generation, Classification and Summarization.","category":"page"},{"location":"#Why-NLPMetrics?","page":"Home","title":"Why NLPMetrics?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To be updated soon...","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To be updated soon...","category":"page"},{"location":"#Example-Use-Case","page":"Home","title":"Example Use-Case","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To be updated soon...","category":"page"}]
}
